{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etarazonav/650044-ABD-ULIMA/blob/main/Notebooks/ABB_SparkSQL1_Aspectos_basicos_DataFrames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img style=\"float: left; padding: 0px 10px 0px 0px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/Universidad_de_Lima_logo.png/220px-Universidad_de_Lima_logo.png\"  width=\"120\" /> Parte 1: Aspectos Básicos de DataFrames en SparkSQL\n",
        "**Profesor:** Enver G. Tarazona Vargas <br>\n",
        "**Curso:** Analítica con Big Data <br>\n",
        "**FACULTAD DE INGENIERÍA - CARRERA DE INGENIERÍA DE SISTEMAS**<br>\n"
      ],
      "metadata": {
        "id": "opOTYvEVHrCc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfxvLhWnksq_"
      },
      "source": [
        "Documentación oficial de SparkSQL:\n",
        "* https://spark.apache.org/docs/latest/sql-ref.html\n",
        "* https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/index.html\n",
        "* https://spark.apache.org/docs/latest/api/python/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P0MOm-vhEvUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54428cc1-9ac7-4a94-fc4e-4ed09d9b8e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Instalación de PySpark (si se está usando Google Colab, por ejemplo)\n",
        "!pip install -q pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii9X8de1X3U_"
      },
      "source": [
        "**Creación de una sesión de Spark SQL**\n",
        "\n",
        "Las aplicaciones de PySpark inician con una sesión de Spark llamada `SparkSession`, que es el punto de entrada a PySpark. Si Spark se corre en un shell (ejecutando: `pyspark`), no es necesario crear esta sesión de Spark dado que el shell crea la variable `spark` automáticamente. Si se corre un programa con `spark-submit` o si se tiene algún otro entorno (como Google Colab) sí es necesario iniciar la variable como se indica a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mNOSiTaOEuCF"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtPuLGzMmY9T"
      },
      "source": [
        "Si se desea especificar el nombre de la aplicación, se puede realizar añadiendo `appName`. Por ejemplo, si se desea el nombre `Aplicacion1`, se utiliza: `spark = SparkSession.builder.appName('Aplicacion1').getOrCreate()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6R2BKpusE7X7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "20feac1a-9947-4142-cc0e-3fd58b261aad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.session.SparkSession"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.session.SparkSession</b><br/>def __init__(sparkContext: SparkContext, jsparkSession: Optional[JavaObject]=None, options: Dict[str, Any]={})</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py</a>The entry point to programming Spark with the Dataset and DataFrame API.\n",
              "\n",
              "A SparkSession can be used to create :class:`DataFrame`, register :class:`DataFrame` as\n",
              "tables, execute SQL over tables, cache tables, and read parquet files.\n",
              "To create a :class:`SparkSession`, use the following builder pattern:\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              ".. autoattribute:: builder\n",
              "   :annotation:\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Create a Spark session.\n",
              "\n",
              "&gt;&gt;&gt; spark = (\n",
              "...     SparkSession.builder\n",
              "...         .master(&quot;local&quot;)\n",
              "...         .appName(&quot;Word Count&quot;)\n",
              "...         .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;)\n",
              "...         .getOrCreate()\n",
              "... )\n",
              "\n",
              "Create a Spark session with Spark Connect.\n",
              "\n",
              "&gt;&gt;&gt; spark = (\n",
              "...     SparkSession.builder\n",
              "...         .remote(&quot;sc://localhost&quot;)\n",
              "...         .appName(&quot;Word Count&quot;)\n",
              "...         .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;)\n",
              "...         .getOrCreate()\n",
              "... )  # doctest: +SKIP</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 166);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "type(spark)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd6nJ9hUYyRx"
      },
      "source": [
        "## 1.&nbsp;Creación de un Data Frame\n",
        "\n",
        "Un DataFrame de PySpark se puede crear usando `spark.createDataFrame`, que utiliza un argumento llamado `schema` para especificar el esquema del DataFrame. Si se omite el esquema, PySpark lo infiere a partir de una muestra de los datos utilizados.\n",
        "\n",
        "Se puede crear DataFrames de varias maneras, como se muestra a continuación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCELWNp3FBvU"
      },
      "source": [
        "### 1.1. Creación por filas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7rMq5XAy_yUA"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Row\n",
        "from datetime import datetime, date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9tIvH9uBuut"
      },
      "source": [
        "Creación usando `Row`, que especifica el esquema en cada fila. Notar que cada fila se trata como si fuera una tupla con nombre."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYuH7YslBo9Q",
        "outputId": "d293e638-7845-4f0b-9844-7dca7a502c99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+------+----------+-------------------+\n",
            "| ID|Valor|Nombre|     Fecha|               Hora|\n",
            "+---+-----+------+----------+-------------------+\n",
            "|  1|  2.0|Carlos|2000-01-01|2000-01-01 12:00:00|\n",
            "|  2|  3.0| María|2000-02-01|2000-01-02 12:00:00|\n",
            "|  4|  5.0| Pedro|2000-03-01|2000-01-03 12:00:00|\n",
            "+---+-----+------+----------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.createDataFrame([\n",
        "    Row(ID=1, Valor=2., Nombre='Carlos', Fecha=date(2000, 1, 1), Hora=datetime(2000, 1, 1, 12, 0)),\n",
        "    Row(ID=2, Valor=3., Nombre='María',  Fecha=date(2000, 2, 1), Hora=datetime(2000, 1, 2, 12, 0)),\n",
        "    Row(ID=4, Valor=5., Nombre='Pedro',  Fecha=date(2000, 3, 1), Hora=datetime(2000, 1, 3, 12, 0))\n",
        "])\n",
        "\n",
        "# Mostrar el DataFrame\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMXRmjE8C_dC",
        "outputId": "e1ef68a9-142b-40b4-d08a-0ade1172f8ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- ID: long (nullable = true)\n",
            " |-- Valor: double (nullable = true)\n",
            " |-- Nombre: string (nullable = true)\n",
            " |-- Fecha: date (nullable = true)\n",
            " |-- Hora: timestamp (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Mostrar el esquema del DataFrame\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXu81FSYB3Xu"
      },
      "source": [
        "Creación usando tuplas y especificando el esquema de manera explícita (con el tipo de dato)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5WWQdD5BozC",
        "outputId": "f70e5998-07f3-483f-facf-09a701c58b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+------+----------+-------------------+\n",
            "| ID|Valor|Nombre|     Fecha|               Hora|\n",
            "+---+-----+------+----------+-------------------+\n",
            "|  1|  2.0|Carlos|2000-01-01|2000-01-01 12:00:00|\n",
            "|  2|  3.0| María|2000-02-01|2000-01-02 12:00:00|\n",
            "|  4|  5.0| Pedro|2000-03-01|2000-01-03 12:00:00|\n",
            "+---+-----+------+----------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.createDataFrame([\n",
        "    (1, 2., 'Carlos', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
        "    (2, 3., 'María',  date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
        "    (4, 5., 'Pedro',  date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
        "], schema='ID long, Valor double, Nombre string, Fecha date, Hora timestamp')\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2paPm27UDila"
      },
      "source": [
        "### 1.2. Creación usando un DataFrame de Pandas\n",
        "\n",
        "Documentación del DataFrame de Pandas: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ko8jcCnz_yRG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1ucpJ14_yPB",
        "outputId": "d661c7b6-00e0-470f-ba0e-967ab156b0f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+------+----------+-------------------+\n",
            "| ID|Valor|Nombre|     Fecha|               Hora|\n",
            "+---+-----+------+----------+-------------------+\n",
            "|  1|  2.0|Carlos|2000-01-01|2000-01-01 12:00:00|\n",
            "|  2|  3.0| María|2000-02-01|2000-01-02 12:00:00|\n",
            "|  3|  4.0| Pedro|2000-03-01|2000-01-03 12:00:00|\n",
            "+---+-----+------+----------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Creación del DataFrame de Pandas\n",
        "pandas_df = pd.DataFrame({\n",
        "    'ID': [1, 2, 3],\n",
        "    'Valor': [2., 3., 4.],\n",
        "    'Nombre': ['Carlos', 'María', 'Pedro'],\n",
        "    'Fecha': [date(2000, 1, 1), date(2000, 2, 1), date(2000, 3, 1)],\n",
        "    'Hora': [datetime(2000, 1, 1, 12, 0), datetime(2000, 1, 2, 12, 0), datetime(2000, 1, 3, 12, 0)]\n",
        "})\n",
        "\n",
        "# Creación del DataFrame de Spark a partir del DataFrame de Pandas\n",
        "df = spark.createDataFrame(pandas_df)\n",
        "\n",
        "# Mostrar el DataFrame\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9kwzRYNnfNO"
      },
      "source": [
        "### 1.3. Creación a partir de un RDD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfkKaGMBrHkA"
      },
      "source": [
        "Si el RDD no tiene esquema, se le tiene que asignar al momento de crear el DataFrame usando `schema`, donde se incluye el nombre del campo y el tipo de dato (string, int, long, double, date, timestamp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RpA1XDFnfnk",
        "outputId": "9bd0136e-f8ef-4b4f-cd61-3956b7ba149e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+\n",
            "|  nombre|edad|\n",
            "+--------+----+\n",
            "|    Juan|  20|\n",
            "|   María|  25|\n",
            "|Victoria|  22|\n",
            "+--------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sc = spark.sparkContext\n",
        "\n",
        "# Creación de un RDD\n",
        "rdd = sc.parallelize([(\"Juan\", 20), (\"María\", 25), (\"Victoria\", 22)])\n",
        "\n",
        "# Creación de DataFrame a partir del RDD\n",
        "df = spark.createDataFrame(rdd,\n",
        "                           schema='nombre string,edad int')\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZqk3x34rEGf"
      },
      "source": [
        "Se le puede asignar esquema al RDD definiendo cada elemento como una fila `Row`, que es similar a una tupla con nombre."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1LsAFtgqdjY",
        "outputId": "f932b410-9944-4244-a188-a82cc48229a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+\n",
            "|nombre|edad|\n",
            "+------+----+\n",
            "|  Juan|  20|\n",
            "| Kiara|  19|\n",
            "| Keiko|  80|\n",
            "+------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "rdd = sc.parallelize([Row(nombre=\"Juan\", edad=20),\n",
        "                      Row(nombre=\"Kiara\", edad=19),\n",
        "                      Row(nombre=\"Keiko\", edad=80)])\n",
        "\n",
        "df = spark.createDataFrame(rdd)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTFlDcYsFK9i"
      },
      "source": [
        "## 2.&nbsp;Carga de Datos a un DataFrame\n",
        "\n",
        "Para más información sobre los formatos mencionados aquí, u otros formatos, consultar estas referencias:\n",
        "* https://spark.apache.org/docs/latest/sql-data-sources.html\n",
        "* https://github.com/apache/spark/blob/master/examples/src/main/python/sql/datasource.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por facilidad se cargará archivos del repositorio usando `wget`. Estos archivos (o carpetas) también pueden ser subidos manualmente a Google Colab. En caso de estar trabajando en un clúster con HDFS, estos archivos deberían estar en el clúster."
      ],
      "metadata": {
        "id": "EUpXPARQg6E-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://raw.githubusercontent.com/etarazonav/650044-ABD-ULIMA/refs/heads/main/Datos/personas.csv\n",
        "!wget -q https://raw.githubusercontent.com/etarazonav/650044-ABD-ULIMA/refs/heads/main/Datos/recursos.zip\n",
        "!unzip -q recursos.zip\n",
        "!wget -q https://raw.githubusercontent.com/etarazonav/650044-ABD-ULIMA/refs/heads/main/Datos/texto-personas.txt\n",
        "!wget -q https://raw.githubusercontent.com/etarazonav/650044-ABD-ULIMA/refs/heads/main/Datos/personas.json\n",
        "!wget -q https://raw.githubusercontent.com/etarazonav/650044-ABD-ULIMA/refs/heads/main/Datos/personas.parquet\n"
      ],
      "metadata": {
        "id": "NA8UQ79Mg0r7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lB8bwN-ssokh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz6KyToAJRug"
      },
      "source": [
        "### 2.1. Lectura de CSV\n",
        "\n",
        "Más información: https://spark.apache.org/docs/latest/sql-data-sources-csv.html\n",
        "\n",
        "Lectura directa sin especificar la estructura. Por defecto asume que el separador es una coma `,`. En este ejemplo el delimitador es `;`, así que al leer no se separa las columnas sino se lee como una sola columna (con nombre `_c0` por defecto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0JJfNMdJRZU",
        "outputId": "39b360a8-a21c-459f-a8a4-68ecca31c8b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                 _c0|\n",
            "+--------------------+\n",
            "| nombre;edad;trabajo|\n",
            "|Jorge;30;Desarrol...|\n",
            "|  María;23;Psicóloga|\n",
            "|    Pedro;25;Abogado|\n",
            "|Jennifer;21;Admin...|\n",
            "|Mariana;23;Influe...|\n",
            "|  Adalí;24;Estilista|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.csv(\"personas.csv\")\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRNRK1UPKSGb"
      },
      "source": [
        "Lectura especificando un delimitador. En este ejemplo, el delimitador es `;`. Los nombres de las columnas se asignan por defecto como `_c0`, `_c1`, `_c2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9_CKcJkKR5n",
        "outputId": "ef80f829-e4f0-4e72-b0eb-4a9f2e158635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+--------------+\n",
            "|     _c0| _c1|           _c2|\n",
            "+--------+----+--------------+\n",
            "|  nombre|edad|       trabajo|\n",
            "|   Jorge|  30| Desarrollador|\n",
            "|   María|  23|     Psicóloga|\n",
            "|   Pedro|  25|       Abogado|\n",
            "|Jennifer|  21|Administradora|\n",
            "| Mariana|  23|    Influencer|\n",
            "|   Adalí|  24|     Estilista|\n",
            "+--------+----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.option(\"delimiter\", \";\").csv(\"personas.csv\")\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV_VfYNOLMbx"
      },
      "source": [
        "Lectura especificando un delimitador y un encabezado (primera fila del CSV)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wiE2kyIKR2O",
        "outputId": "5177c898-f235-4bc9-f807-42015674f653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+--------------+\n",
            "|  nombre|edad|       trabajo|\n",
            "+--------+----+--------------+\n",
            "|   Jorge|  30| Desarrollador|\n",
            "|   María|  23|     Psicóloga|\n",
            "|   Pedro|  25|       Abogado|\n",
            "|Jennifer|  21|Administradora|\n",
            "| Mariana|  23|    Influencer|\n",
            "|   Adalí|  24|     Estilista|\n",
            "+--------+----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.options(delimiter=\";\", header=True).csv(\"personas.csv\")\n",
        "\n",
        "# También se podría especificar cada opción por separado:\n",
        "# df = spark.read.option(\"delimiter\", \";\").option(\"header\", True).csv(\"personas.csv\")\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wjwtHbVQX8A",
        "outputId": "9a28e435-c8e4-4d9a-e4e6-1d69058fc22b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+--------------+\n",
            "|  nombre|edad|       trabajo|\n",
            "+--------+----+--------------+\n",
            "|   Jorge|  30| Desarrollador|\n",
            "|   María|  23|     Psicóloga|\n",
            "|   Pedro|  25|       Abogado|\n",
            "|Jennifer|  21|Administradora|\n",
            "| Mariana|  23|    Influencer|\n",
            "|   Adalí|  24|     Estilista|\n",
            "+--------+----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Otra alternativa de lectura es la siguiente:\n",
        "df = spark.read.load(\"personas.csv\",\n",
        "                     format=\"csv\", sep=\";\",\n",
        "                     inferSchema=\"true\", header=\"true\")\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hddsj4hQJRMv"
      },
      "source": [
        "Lectura de varios archivos CSV en una carpeta. Se debe asegurar de que solo existan archivos CSV en la carpeta y que el formato sea similar, para que puedan ser leidos y cargados adecuadamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-L6v76lJjwx",
        "outputId": "d6d1674d-dd9d-4958-b69f-b8b1f34f2a3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------------+\n",
            "| nombre|edad|       trabajo|\n",
            "+-------+----+--------------+\n",
            "| Carlos|  24|     Ingeniero|\n",
            "|Mariana|  22|     Contadora|\n",
            "| Sharon|  28|Administradora|\n",
            "|  Jorge|  30| Desarrollador|\n",
            "|  María|  32|     Ingeniero|\n",
            "|  Pedro|  25|       Abogado|\n",
            "|  Mario|  25|       Abogado|\n",
            "| Salomé|  22|        Modelo|\n",
            "| Fershi|  19|    Influencer|\n",
            "+-------+----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Nombre de la carpeta donde se encuentran varios CSV con similar estructura\n",
        "carpetaDatos = \"recursos\"\n",
        "\n",
        "# Lectura de varios csv en un solo DataFrame especificando la carpeta\n",
        "df = spark.read.option(\"delimiter\", \";\").option(\"header\", True).csv(\"recursos\")\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCAXxsQTOzow"
      },
      "source": [
        "### 2.2. Lectura de TXT\n",
        "\n",
        "Más información: https://spark.apache.org/docs/latest/sql-data-sources-text.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbfxASdbRvdi",
        "outputId": "bb1d2548-0d7f-4cbe-da65-dc3cbb0f239c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|        value|\n",
            "+-------------+\n",
            "|   Maikol, 29|\n",
            "|   Andrés, 30|\n",
            "|Justencio, 19|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.text(\"texto-personas.txt\")\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrdvLsWlSRgO"
      },
      "source": [
        "Se puede indicar el separador de línea (fila) usando la opción `lineSep`. Por defecto se asume `\\n`, `\\r\\n` o `\\r`. Para el siguiente ejemplo se\n",
        "forzará el uso de la `,` como si fuera un separador de línea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JRqLKtNSLm1",
        "outputId": "05d8509f-1194-417f-d55d-a324e1aa91ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|         value|\n",
            "+--------------+\n",
            "|        Maikol|\n",
            "|    29\\nAndrés|\n",
            "| 30\\nJustencio|\n",
            "|            19|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.text(\"texto-personas.txt\", lineSep=\",\")\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhyO14B3TlMj"
      },
      "source": [
        "### 2.3. Lectura de JSON\n",
        "\n",
        "Más información: https://spark.apache.org/docs/latest/sql-data-sources-json.html\n",
        "\n",
        "Notar que el archivo JSON no es un típico JSON, sino que cada línea debe contener un objeto JSON válido, separado y auto contenido. A este formato se le suele llamar \"JSON Lines text format\" o \"newline-delimited JSON\" (https://jsonlines.org/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjxNMXxZTCyX",
        "outputId": "05fc6e86-c159-4f10-e5c4-d3c1c4934a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+------+\n",
            "|edad|estatura|nombre|\n",
            "+----+--------+------+\n",
            "|NULL|    NULL| Pedro|\n",
            "|  30|    NULL| María|\n",
            "|  25|    NULL|Carlos|\n",
            "|NULL|     162|Teresa|\n",
            "+----+--------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.json(\"personas.json\")\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_yFhFuFXxYL",
        "outputId": "ca6c7400-b63f-477c-940e-20d0f3dba006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- edad: long (nullable = true)\n",
            " |-- estatura: long (nullable = true)\n",
            " |-- nombre: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Esquema inferido\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hBoN6EbX_ZH"
      },
      "source": [
        "De manera alternativa, se puede crear un DataFrame utilizando un RDD que contiene objetos JSON como cadenas de caracteres."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQs9_7c5TCvB",
        "outputId": "d7d4dd70-95ce-4b56-a1e0-03aef34171fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['{\"nombre\":\"Juan\",\"direccion\":{\"ciudad\":\"Lima\",\"distrito\":\"Miraflores\"}}',\n",
              " '{\"nombre\":\"Camila\",\"direccion\":{\"ciudad\":\"Arequipa\",\"distrito\":\"Cercado\"}}']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "datos = ['{\"nombre\":\"Juan\",\"direccion\":{\"ciudad\":\"Lima\",\"distrito\":\"Miraflores\"}}',\n",
        "         '{\"nombre\":\"Camila\",\"direccion\":{\"ciudad\":\"Arequipa\",\"distrito\":\"Cercado\"}}']\n",
        "\n",
        "sc = spark.sparkContext\n",
        "rdd = sc.parallelize(datos)\n",
        "rdd.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCLVkCxATCsX",
        "outputId": "688fc534-881a-4738-9d93-0dcac3bb58b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------+\n",
            "|          direccion|nombre|\n",
            "+-------------------+------+\n",
            "| {Lima, Miraflores}|  Juan|\n",
            "|{Arequipa, Cercado}|Camila|\n",
            "+-------------------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.json(rdd)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdT42KvIayBv"
      },
      "source": [
        "### 2.4. Lectura de Parquet\n",
        "\n",
        "Más información: https://spark.apache.org/docs/latest/sql-data-sources-parquet.html\n",
        "\n",
        "Parquet es un formato columnar soportado por muchos sistemas de procesamiento y análisis de datos para Big Data. Spark SQL al leer archivos Parquet preserva el esquema de los datos originales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vcLLkAeTCpt",
        "outputId": "635be8aa-dff1-46f1-febc-182d979d5e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-------------+\n",
            "|nombre|edad|      trabajo|\n",
            "+------+----+-------------+\n",
            "| Jorge|  30|Desarrollador|\n",
            "| María|  32|    Ingeniero|\n",
            "| Pedro|  25|      Abogado|\n",
            "+------+----+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.load(\"personas.parquet\")\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5OgfoVPGWb3"
      },
      "source": [
        "## 3.&nbsp;Visualización de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "W81qFnM8i2DE"
      },
      "outputs": [],
      "source": [
        "# Lectura de un dataframe de un conjunto de CSVs\n",
        "df = spark.read.load(\"recursos\", format=\"csv\", sep=\";\",\n",
        "                     inferSchema=\"true\", header=\"true\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7ZHxhdKi2tm"
      },
      "source": [
        "Si se desea visualizar el contenido del dataframe escribiendo únicamente el nombre del DataFrame (en un cuaderno de Jupyter) se puede activar la opción `spark.sql.repl.eagerEval.enabled`. Para todo lo demás, no es necesario activar esta opción."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "21Fgoa7T_yBT"
      },
      "outputs": [],
      "source": [
        "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEnlJV4RlnUn"
      },
      "source": [
        "**Visualización del DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "rJQ2SgBjiFek",
        "outputId": "05e04bc8-5672-4a31-cdca-b50d4caa50cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[nombre: string, edad: int, trabajo: string]"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>nombre</th><th>edad</th><th>trabajo</th></tr>\n",
              "<tr><td>Carlos</td><td>24</td><td>Ingeniero</td></tr>\n",
              "<tr><td>Mariana</td><td>22</td><td>Contadora</td></tr>\n",
              "<tr><td>Sharon</td><td>28</td><td>Administradora</td></tr>\n",
              "<tr><td>Jorge</td><td>30</td><td>Desarrollador</td></tr>\n",
              "<tr><td>Mar&iacute;a</td><td>32</td><td>Ingeniero</td></tr>\n",
              "<tr><td>Pedro</td><td>25</td><td>Abogado</td></tr>\n",
              "<tr><td>Mario</td><td>25</td><td>Abogado</td></tr>\n",
              "<tr><td>Salom&eacute;</td><td>22</td><td>Modelo</td></tr>\n",
              "<tr><td>Fershi</td><td>19</td><td>Influencer</td></tr>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Si se activa la opción anterior, se puede usar el nombre del dataframe solito\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lj-Gup7jWmn"
      },
      "source": [
        "Visualización de una determinada cantidad de filas usando `show(N)`, donde `N` es el número de filas. Si no se especifica, por defecto muestra las 20 primeras filas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjow8FJJhUGA",
        "outputId": "59d18bb7-dbd6-48fb-fc5a-d69da24ec4a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------------+\n",
            "| nombre|edad|       trabajo|\n",
            "+-------+----+--------------+\n",
            "| Carlos|  24|     Ingeniero|\n",
            "|Mariana|  22|     Contadora|\n",
            "| Sharon|  28|Administradora|\n",
            "|  Jorge|  30| Desarrollador|\n",
            "|  María|  32|     Ingeniero|\n",
            "+-------+----+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCPgh_sXj6Ri"
      },
      "source": [
        "Las filas pueden ser mostradas de manera vertical con la opción `vertical`. Esta forma de visualizar suele ser útil cuando las filas son muy largas para ser mostradas horizontalmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3mMJ37uj631",
        "outputId": "2ca91c4b-a7a7-46a7-e9ce-fcc34f464477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0------------\n",
            " nombre  | Carlos    \n",
            " edad    | 24        \n",
            " trabajo | Ingeniero \n",
            "-RECORD 1------------\n",
            " nombre  | Mariana   \n",
            " edad    | 22        \n",
            " trabajo | Contadora \n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(2, vertical=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhkTU-eCjohP"
      },
      "source": [
        "**Esquema del DataFrame**\n",
        "\n",
        "Se puede visualizar el nombre de las columnas y la estructura de la tabla usando `columns` y `printSchema`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_lhEEjFjzCP",
        "outputId": "84925c1a-e0ec-4118-e028-81413aa0c571"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nombre', 'edad', 'trabajo']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Nombres de columnas\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRuwICtSEuCM",
        "outputId": "e9a9f67d-1822-4922-ab4d-043943fcea7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- nombre: string (nullable = true)\n",
            " |-- edad: integer (nullable = true)\n",
            " |-- trabajo: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Mostrar esquema\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25dA8Q3MkcLa"
      },
      "source": [
        "**Resumen de los datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNfx6YsSEuCN",
        "outputId": "3f0bc05a-d585-41ee-8f48-18a43aeab6e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------------------+-------+\n",
            "|summary|nombre|              edad|trabajo|\n",
            "+-------+------+------------------+-------+\n",
            "|  count|     9|                 9|      9|\n",
            "|   mean|  NULL| 25.22222222222222|   NULL|\n",
            "| stddev|  NULL|4.1466184348749096|   NULL|\n",
            "|    min|Carlos|                19|Abogado|\n",
            "|    max|Sharon|                32| Modelo|\n",
            "+-------+------+------------------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSjdtEG8Z2UB"
      },
      "source": [
        "## 4.&nbsp;Selección y acceso a los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmQiPV_d0MCp"
      },
      "source": [
        "Los DataFrames se evalúan de manera ociosa (\"lazy\") y cuando se selecciona una columna no se realiza el cálculo sino que solo se retorna una instancia de tipo `Column`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7Cf-nU40iX1",
        "outputId": "68e5887b-54af-4ff7-cfd7-fdffb6a714bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'nombre'>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "df.nombre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0frA8i1o7hi9"
      },
      "source": [
        "### 4.1. Selección de columnas\n",
        "\n",
        "Para el acceso a una columna o varias columnas se utiliza `DataFrame.select()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsb-0P3BEuCN",
        "outputId": "288e5609-ec22-49f5-f2e3-511ae587e5b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "|edad|\n",
            "+----+\n",
            "|  24|\n",
            "|  22|\n",
            "|  28|\n",
            "+----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select('edad').show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EIpOA9u0VMe",
        "outputId": "84ebffc2-5ee1-47e6-d6af-5451d3ad135b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+\n",
            "| nombre|edad|\n",
            "+-------+----+\n",
            "| Carlos|  24|\n",
            "|Mariana|  22|\n",
            "| Sharon|  28|\n",
            "+-------+----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(['nombre', 'edad']).show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no410D_4wsFj",
        "outputId": "09019490-4f41-4281-f473-65fa612b1472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------+\n",
            "| nombre|       trabajo|\n",
            "+-------+--------------+\n",
            "| Carlos|     Ingeniero|\n",
            "|Mariana|     Contadora|\n",
            "| Sharon|Administradora|\n",
            "+-------+--------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(\"nombre\", \"trabajo\").show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PzB5PJ149gW"
      },
      "source": [
        "### 4.2. Recolección de datos\n",
        "\n",
        "`DataFrame.collect()` recolecta los datos distribuidos y los envía al driver como datos locales en Python. Esto puede generar errores de falta de memoria cuando el dataset es muy grande para caber en el driver, ya que se recolecta todos los datos de los ejecutores hacia el driver."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCDv1FhO5CX_",
        "outputId": "c90a0354-affd-4bc8-ba24-744bc75decd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(nombre='Carlos', edad=24, trabajo='Ingeniero'),\n",
              " Row(nombre='Mariana', edad=22, trabajo='Contadora'),\n",
              " Row(nombre='Sharon', edad=28, trabajo='Administradora'),\n",
              " Row(nombre='Jorge', edad=30, trabajo='Desarrollador'),\n",
              " Row(nombre='María', edad=32, trabajo='Ingeniero'),\n",
              " Row(nombre='Pedro', edad=25, trabajo='Abogado'),\n",
              " Row(nombre='Mario', edad=25, trabajo='Abogado'),\n",
              " Row(nombre='Salomé', edad=22, trabajo='Modelo'),\n",
              " Row(nombre='Fershi', edad=19, trabajo='Influencer')]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "df.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbatpzeH5J4a"
      },
      "source": [
        "Para evitar la excepción de falta de memoria, se puede usar `DataFrame.take(N)`, `DataFrame.head(N)` o `DataFrame.tail(N)`, donde `N` es el número de filas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl2Ws7jz5Koe",
        "outputId": "beedf97e-e338-4f00-c391-c1728d1a7a43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(nombre='Carlos', edad=24, trabajo='Ingeniero'),\n",
              " Row(nombre='Mariana', edad=22, trabajo='Contadora'),\n",
              " Row(nombre='Sharon', edad=28, trabajo='Administradora')]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "df.take(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89ewNbet5OR-",
        "outputId": "7c68e6f6-43ef-4d11-e4b5-fe72d315e3ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(nombre='Carlos', edad=24, trabajo='Ingeniero'),\n",
              " Row(nombre='Mariana', edad=22, trabajo='Contadora'),\n",
              " Row(nombre='Sharon', edad=28, trabajo='Administradora')]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WVV36uQ5OIm",
        "outputId": "547b4e13-00be-4730-f10f-0e4606c34c9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(nombre='Mario', edad=25, trabajo='Abogado'),\n",
              " Row(nombre='Salomé', edad=22, trabajo='Modelo'),\n",
              " Row(nombre='Fershi', edad=19, trabajo='Influencer')]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "df.tail(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUjCWO_551UH"
      },
      "source": [
        "La extracción de datos para procesarlos \"manualmente\" se puede realizar extrayendo las filas `Row` a través de índices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nv9dbezEuCO",
        "outputId": "815adc68-87f0-4760-ba00-a24b8b75908c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(nombre='Mariana', edad=22, trabajo='Contadora')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Extraccion de filas\n",
        "df.head(2)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uAQDD0oFt8d",
        "outputId": "081de45a-6791-4051-b31c-121a805bf47e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# Recuperación de valores\n",
        "dato = df.head(2)[1]\n",
        "dato.edad     # Equivalente a dato[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "cnyHQ4M2V3k0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4387ec19-9e44-4de4-dd0f-8567fb8126dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'nombre': 'Mariana', 'edad': 22, 'trabajo': 'Contadora'}\n"
          ]
        }
      ],
      "source": [
        "# Se puede convertir el dato en un diccionario\n",
        "dato = df.head(2)[1].asDict()\n",
        "print(dato)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h06aXdQa7crF"
      },
      "source": [
        "### 4.3. Creación de nuevas columnas\n",
        "\n",
        "Para crear una nueva columna se utiliza `withColumn`. Notar que el DataFrame es inmutable: si se desea almacenar el resultado se debe crear un nuevo DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeWWF9-a8W3J",
        "outputId": "045a9d63-5545-4c8e-d207-56d3fb938e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------------+--------------+\n",
            "| nombre|edad|       trabajo|año nacimiento|\n",
            "+-------+----+--------------+--------------+\n",
            "| Carlos|  24|     Ingeniero|          1999|\n",
            "|Mariana|  22|     Contadora|          2001|\n",
            "| Sharon|  28|Administradora|          1995|\n",
            "+-------+----+--------------+--------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Crear una nueva columna de año de nacimiento (asumiendo que es el año 2023)\n",
        "df2 = df.withColumn('año nacimiento', 2023-df['edad'])\n",
        "\n",
        "df2.show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiG4Kb6p7Z1L",
        "outputId": "85a11e41-77d5-4d4f-9a7b-7362369e5552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------------+----------+\n",
            "| nombre|edad|       trabajo|nombre_may|\n",
            "+-------+----+--------------+----------+\n",
            "| Carlos|  24|     Ingeniero|    CARLOS|\n",
            "|Mariana|  22|     Contadora|   MARIANA|\n",
            "| Sharon|  28|Administradora|    SHARON|\n",
            "+-------+----+--------------+----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import upper\n",
        "\n",
        "# Crear una nueva columna con la columna \"nombre\" en mayúsculas\n",
        "df.withColumn('nombre_may', upper(df['nombre'])).show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qr1_4il-hvd"
      },
      "source": [
        "Se puede cambiar el nombre de una columna utilizando `withColumnRenamed`. Notar que para almacenar el nombre cambiado se debe crear un nuevo DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_IRoqZN7aVm",
        "outputId": "7370813e-137e-4ea4-d7d3-4abc0edd2643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------------+\n",
            "| nombre|años|       trabajo|\n",
            "+-------+----+--------------+\n",
            "| Carlos|  24|     Ingeniero|\n",
            "|Mariana|  22|     Contadora|\n",
            "| Sharon|  28|Administradora|\n",
            "+-------+----+--------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cambiar nombre a una columna\n",
        "df2 = df.withColumnRenamed('edad', 'años')\n",
        "\n",
        "df2.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANFfwfcoalJm"
      },
      "source": [
        "## 5.&nbsp;Modificación del esquema\n",
        "\n",
        "Si Spark no infiere adecuadamente los datos, o si se desea modificar el tipo de dato de las columnas, se puede crear un nuevo esquema especificando los tipos de datos.\n",
        "\n",
        "Se puede ver los tipos de datos existentes en: https://spark.apache.org/docs/latest/sql-ref-datatypes.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "LquLA4Z-A0wD"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructField, StructType\n",
        "\n",
        "# Importar los tipos de datos que se va a utilizar\n",
        "from pyspark.sql.types import StringType, FloatType"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxtHYNQ5CXJI"
      },
      "source": [
        "En este ejemplo se intenta modificar lo siguiente:\n",
        "* `edad` con tipo float\n",
        "* cambiar el nombre del tercer campo de \"trabajo\" a \"ocupación\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "KySO8n6xar1s"
      },
      "outputs": [],
      "source": [
        "# Creación del nuevo esquema\n",
        "campos = [StructField('nombre', StringType(), True),\n",
        "          StructField('edad', FloatType(), True),\n",
        "          StructField('ocupación', StringType(), True),\n",
        "         ]\n",
        "esquema2 = StructType(fields = campos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgrZJEs8EuCO",
        "outputId": "0bc5b7f4-5d8d-41e9-edad-7d5006109d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- nombre: string (nullable = true)\n",
            " |-- edad: float (nullable = true)\n",
            " |-- ocupación: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Lectura de los datos asignando el nuevo esquema\n",
        "df2 = spark.read.load(\"recursos\", format=\"csv\", sep=\";\",\n",
        "                     schema=esquema2, header=\"true\")\n",
        "\n",
        "# Mostrar el nuevo esquema\n",
        "df2.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9mjKcJGCsp7",
        "outputId": "347d68d5-1141-4703-fd61-1d0c68b5e575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------------+\n",
            "| nombre|edad|     ocupación|\n",
            "+-------+----+--------------+\n",
            "| Carlos|24.0|     Ingeniero|\n",
            "|Mariana|22.0|     Contadora|\n",
            "| Sharon|28.0|Administradora|\n",
            "+-------+----+--------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df2.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBC7HBXZC2y0"
      },
      "source": [
        "## 6.&nbsp;Almacenamiento del DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZT7cDoWECyR"
      },
      "source": [
        "### 6.1. Conversión a DataFrame de Pandas\n",
        "\n",
        "Un DataFrame de Spark puede convertirse a un DataFrame de Pandas, para poder utilizar el API de pandas (y eventualmente poder hacer figuras y demás). Notar que `toPandas` recolecta todos los datos al driver, de tal modo que puede fácilmente causar errores de tamaño de memoria en el driver cuando se tiene muchos datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "sRkrNWjdDZR2"
      },
      "outputs": [],
      "source": [
        "df_pandas = df.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "iJgVFmAjDzoi",
        "outputId": "983c4c03-4cda-4cd5-8d7e-99be50b703f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    nombre  edad         trabajo\n",
              "0   Carlos    24       Ingeniero\n",
              "1  Mariana    22       Contadora\n",
              "2   Sharon    28  Administradora"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6152a3c-a6a0-46b0-b113-90f7244afcf1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nombre</th>\n",
              "      <th>edad</th>\n",
              "      <th>trabajo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Carlos</td>\n",
              "      <td>24</td>\n",
              "      <td>Ingeniero</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mariana</td>\n",
              "      <td>22</td>\n",
              "      <td>Contadora</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sharon</td>\n",
              "      <td>28</td>\n",
              "      <td>Administradora</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6152a3c-a6a0-46b0-b113-90f7244afcf1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6152a3c-a6a0-46b0-b113-90f7244afcf1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6152a3c-a6a0-46b0-b113-90f7244afcf1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f09aa48e-a627-4a92-90be-9ce8df250d26\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f09aa48e-a627-4a92-90be-9ce8df250d26')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f09aa48e-a627-4a92-90be-9ce8df250d26 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_pandas",
              "summary": "{\n  \"name\": \"df_pandas\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"nombre\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Salom\\u00e9\",\n          \"Mariana\",\n          \"Pedro\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"edad\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          24,\n          22,\n          25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trabajo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Ingeniero\",\n          \"Contadora\",\n          \"Modelo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "df_pandas.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11FoJyRYEkzI"
      },
      "source": [
        "### 6.2. Almacenamiento en disco\n",
        "\n",
        "Al almacenar como CSV se puede especificar las mismas opciones que para lectura (por ejemplo, `header`). Se asigna el nombre de una carpeta, la cual contendrá un archivo vacío llamado `_SUCCESS`, que indica el éxito de la grabación, así como múltiples archivos csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "8c1KwdgBEy9_"
      },
      "outputs": [],
      "source": [
        "df.write.options(header=True).csv(\"salida_csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBQfXAUjJEnr"
      },
      "source": [
        "La salida también puede ser parquet. Igualmente, se indica el nombre de la carpeta de salida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "YwbqaU-5DZL_"
      },
      "outputs": [],
      "source": [
        "df.write.parquet(\"salida_parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF41xv_6JlOg"
      },
      "source": [
        "Otro formato de salida es ORC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "ceF1N6j-JfcE"
      },
      "outputs": [],
      "source": [
        "df.write.orc(\"salida_orc\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}