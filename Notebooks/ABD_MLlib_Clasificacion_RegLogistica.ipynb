{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etarazonav/650044-ABD-ULIMA/blob/main/Notebooks/ABD_MLlib_Clasificacion_RegLogistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img style=\"float: left; padding: 0px 10px 0px 0px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/Universidad_de_Lima_logo.png/220px-Universidad_de_Lima_logo.png\"  width=\"120\" />  MLlib: Clasificación (I)\n",
        "**Profesor:** Enver G. Tarazona Vargas <br>\n",
        "**Curso:** Analítica con Big Data <br>\n",
        "**FACULTAD DE INGENIERÍA - CARRERA DE INGENIERÍA DE SISTEMAS**<br>"
      ],
      "metadata": {
        "id": "C7xq3v-IbP9Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYz2sThRnpTM"
      },
      "source": [
        "# Ejemplo 1: Regresión Logística\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNAe4ci2nsSz"
      },
      "source": [
        "# Solo si se corre en Google Colab\n",
        "!pip install -q pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqrK162NnpTQ"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de archivos\n",
        "!wget -q https://raw.githubusercontent.com/etarazonav/650044-ABD-ULIMA/refs/heads/main/Datos/titanic.csv"
      ],
      "metadata": {
        "id": "YPkcxzKgHNQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDxekeg8slrR"
      },
      "source": [
        "## 1. Lectura de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic36u1utq00Y"
      },
      "source": [
        "Se utilizará los datos del Titanic. Estos datos tienen la siguiente estructura:\n",
        "* Sobrevive: 0 = No, 1 = Sí\n",
        "* Clase: clase del pasajero (1 = 1a, 2 = 2da, 3 = 3a)\n",
        "* Genero\n",
        "* Sibsp: Número de hermanos + esposo(a) a bordo\n",
        "* Parch: Número de padres + hijos a bordo\n",
        "* Boleto: Número de boleto\n",
        "* Precio: Precio del boleto\n",
        "* Cabina\n",
        "* PuertoEmb: puerto de embarque (C = Cherbourg; Q = Queenstown; S = Southampton)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcMzDVPQr4gG",
        "collapsed": true
      },
      "source": [
        "df = spark.read.csv('titanic.csv', inferSchema=True, header=True)\n",
        "\n",
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do8kJg-HnpTe"
      },
      "source": [
        "# Esquema\n",
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxJU7ArUsvDM"
      },
      "source": [
        "## 2. Pre-procesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se desea predecir la variable `Sobrevive` usando las variables `Clase`, `Genero`, `Edad`, `SibSp`, `ParCh`, `Precio`, `PuertoEmb`. Por tanto, se reducirá el DataFrame a solo estas variables (columnas).\n",
        "\n",
        "De manera arbitraria se eliminará los valores nulos (se puede realizar un mayor análisis de estos valores, pero aquí por facilidad se eliminará todas las filas que contengan algún nulo)"
      ],
      "metadata": {
        "id": "1pr6NqYkhSrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar solo algunas columnas\n",
        "df = df.select(['Clase', 'Genero', 'Edad', 'SibSp', 'ParCh', 'Precio', 'PuertoEmb',\n",
        "                'Sobrevive'])\n",
        "\n",
        "# Eliminar filas con datos faltantes\n",
        "df = df.na.drop()"
      ],
      "metadata": {
        "id": "vMtsL-gQhwy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se separará los datos en entrenamiento (train) y prueba o evaluación (test)"
      ],
      "metadata": {
        "id": "wWe4DWm4iygq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kPNqj91npTk"
      },
      "source": [
        "# Separación de datos en entrenamiento (70%) y prueba (30%)\n",
        "df_train, df_test = df.randomSplit([0.7,0.3])\n",
        "\n",
        "# Mostrar algunos datos de entrenamiento\n",
        "df_train.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc2ZAtBXnpTp"
      },
      "source": [
        "### Conversión de datos categóricos en one-hot encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay dos columnas con datos categóricos: `PuertoEmb` y `Genero`. Estas columnas serán convertidas en numéricas usando \"One-Hot Encoding\". Con este fin, primero se les asignará un valor o índice (a través de `StringIndexer`) y luego recién se aplicará `OneHotEncoder`.\n",
        "\n",
        "Por ejemplo, para el puerto de embarque, que tiene 3 valores categóricos, la primera etapa asigna valores numéricos de la siguiente forma: $C=0$, $S=1$, $Q=2$. Luego one-hot encoding crea 3 nuevas columnas con un valor $1$ si corresponde a ese valor, o $0$ si no corresponde a ese valor.\n",
        "\n",
        "| PuertoEmb | C | S | Q |\n",
        "| --- | --- | --- | --- |\n",
        "| C | 1 | 0 | 0 |\n",
        "| S | 0 | 1 | 0 |\n",
        "| Q | 0 | 0 | 1 |\n",
        "\n"
      ],
      "metadata": {
        "id": "NdrnN5v8jLpc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyoyAio3npTp"
      },
      "source": [
        "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n",
        "                                OneHotEncoder,StringIndexer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignación de índices a \"género\"\n",
        "genero_indexer = StringIndexer(inputCol='Genero', outputCol='GeneroIndex')\n",
        "# Conversión de cada índice en \"one-hot encoding\"\n",
        "genero_onehot = OneHotEncoder(inputCol='GeneroIndex',outputCol='GeneroVec')"
      ],
      "metadata": {
        "id": "qygehlEJmqyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Muofid_3npTr"
      },
      "source": [
        "# Conversión de valores de puerto en \"índices\" y luego en \"one-hot encoding\"\n",
        "puerto_indexer = StringIndexer(inputCol='PuertoEmb',outputCol='PuertoIndex')\n",
        "puerto_onehot = OneHotEncoder(inputCol='PuertoIndex',outputCol='PuertoVec')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La columna atributos, que necesita Spark MLlib, se generará utilizando las variables escogidas, pero reemplazando `Genero` y `PuertoEmb` por sus versiones con one-hot encoding."
      ],
      "metadata": {
        "id": "ysaZsSscnBSK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkI8KFoJnpTw"
      },
      "source": [
        "# Vector que agrupa todos los atributos\n",
        "vassembler = VectorAssembler(inputCols=['Clase', 'GeneroVec', 'PuertoVec', 'Edad',\n",
        "                                        'SibSp', 'ParCh', 'Precio'],\n",
        "                             outputCol='atributos')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30PGtDe_npT0"
      },
      "source": [
        "## 3. Creación de un pipeline y Entrenamiento\n",
        "\n",
        "En este ejemplo se utilizará la regresión logística como clasificador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oi0eHTEnpT0"
      },
      "source": [
        "# Modelo de regresión logística\n",
        "modelo_reglog = LogisticRegression(featuresCol='atributos', labelCol='Sobrevive',\n",
        "                                   predictionCol='Prediccion')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un pipeline genera etapas que serán aplicadas a todos los datos (como un flujo de operaciones). En este caso el pipeline contiene 6 operaciones que se realizan en forma consecutiva, de la siguiente manera:\n",
        "* Conversión de `genero` en índice y luego en one-hot encoding\n",
        "* Conversión de `puerto` en índice y luego en one-hot encoding\n",
        "* Ensamble del vector de atributos\n",
        "* Aplicación de los datos (y entrenamiento) al modelo de regresión logística"
      ],
      "metadata": {
        "id": "8fnvFuY5nfCn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge3zIbJ-npT2"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Definición de las etapas (pipeline)\n",
        "pipeline = Pipeline(stages=[genero_indexer, genero_onehot,\n",
        "                            puerto_indexer, puerto_onehot,\n",
        "                            vassembler, modelo_reglog])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnsFBZHknpT9"
      },
      "source": [
        "# Aplicación de los datos de entrenamiento al pipeline creado\n",
        "modelo = pipeline.fit(df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlgUFUQZviuJ"
      },
      "source": [
        "# Etapas del modelo creado (usando el pipeline)\n",
        "# modelo.stages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVTHoxdbxwPK"
      },
      "source": [
        "### Métricas para el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfyDtz57yBo7"
      },
      "source": [
        "# Recuperación del modelo de regresión logística\n",
        "reglog = modelo.stages[5]\n",
        "reglog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVbAyq2Jyf5r"
      },
      "source": [
        "# Predicciones para el conjunto de entrenamiento\n",
        "reglog.summary.predictions.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J-pT6b4x_cP"
      },
      "source": [
        "# True Positives (por etiqueta)\n",
        "print(\"TP para prueba:\", reglog.summary.truePositiveRateByLabel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# False Positives (por etiqueta)\n",
        "print(\"FP para prueba:\", reglog.summary.falsePositiveRateByLabel)"
      ],
      "metadata": {
        "id": "cyTKT1LhogjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1dcoZ6bucEW"
      },
      "source": [
        "# Métricas para el conjunto de entrenamiento\n",
        "accuracy = reglog.summary.accuracy\n",
        "AUC = reglog.summary.areaUnderROC\n",
        "\n",
        "print(\"Exactitud en el conjunto de entrenamiento:\", accuracy)\n",
        "print(\"Área bajo la curva ROC en el conjunto de entrenamiento:\", AUC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Curva ROC usando Python"
      ],
      "metadata": {
        "id": "lMEcMMJb4y7Y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEBmeCt1wdZW"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Curva ROC\n",
        "roc = reglog.summary.roc.collect()\n",
        "# Ejemplo de salidas\n",
        "roc[0:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(roc); FPR = np.zeros(n); TPR = np.zeros(n)\n",
        "for idx, elem in enumerate(roc):\n",
        "  FPR[idx] = elem.FPR\n",
        "  TPR[idx] = elem.TPR\n",
        "plt.plot(FPR, TPR)\n",
        "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YKX3fle649Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpLvhyUmudL-"
      },
      "source": [
        "## 4. Predicción y Evaluación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-mZmxSRnpT_"
      },
      "source": [
        "# Aplicar el modelo a los datos de prueba (test)\n",
        "resultado = modelo.transform(df_test)\n",
        "\n",
        "# Resultados\n",
        "resultado.select('Sobrevive','Prediccion').show(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUhxZ50K0FhR"
      },
      "source": [
        "# type(resultado)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB7UdQy_npUB"
      },
      "source": [
        "from pyspark.ml.evaluation import (BinaryClassificationEvaluator,\n",
        "                                   MulticlassClassificationEvaluator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fWYl0cDnpUD"
      },
      "source": [
        "evaluador1 = BinaryClassificationEvaluator(rawPredictionCol='Prediccion',\n",
        "                                           labelCol='Sobrevive',\n",
        "                                           metricName='areaUnderROC')\n",
        "AUC = evaluador1.evaluate(resultado)\n",
        "print(\"Área bajo la curva ROC en el conjunto de prueba:\", AUC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk2ilB7LnpUH"
      },
      "source": [
        "# Evaluador de la exactitud (accuracy)\n",
        "evaluador2 = MulticlassClassificationEvaluator(predictionCol='Prediccion',\n",
        "                                               labelCol='Sobrevive',\n",
        "                                               metricName='accuracy')\n",
        "exactitud = evaluador2.evaluate(resultado)\n",
        "print(\"Exactitud en el conjunto de prueba:\", exactitud)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YH1gOhjI6QPk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}